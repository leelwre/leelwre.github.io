<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>共空间模式（common spatial pattern, CSP)</title>
      <link href="/BCI/CSP.html"/>
      <url>/BCI/CSP.html</url>
      
        <content type="html"><![CDATA[<center><font face = "黑体" size = 6><strong>共空间模式滤波：一种脑电信号解码方法</strong></font></center><h1 id="写在前面的话"><font size = 4>写在前面的话</font></h1><p>  本文主要基于swolf的博客中的一篇文章<a href="https://mrswolf.github.io/zh-cn/2019/01/06/%E8%AF%A6%E8%A7%A3CSP/" target="_blank" rel="noopener">详解CSP</a>完成，且仅详细推导了其中前两种表述形式，是笔者在学习了《矩阵理论》课程后对学习结果进行应用的一种记录。与swolf文章的主要区别在于补充了其中一些省略的推导步骤，最后参考<a href="#2">[2]</a>中的一幅图进行计算与结果展示，并附上了代码。</p><h1 id="摘要"><font size = 4>摘要</font></h1><p>  空间滤波器对于分析脑电信号、提高信噪比非常有效。其中，共空间模式是最常用的一类空间滤波算法，尤其在运动想象范式分类上具有较好的效果，是运动想象范式的基准算法之一。因此，本文结合矩阵理论知识，从共空间模式的原始算法出发，逐步推导计算，并介绍其第二种表述形式，旨在阐明这一算法的数学思想，最后，结合少量模拟样本，更直观地展示了该算法的作用。</p><h1 id="一问题及背景"><font size = 4>一、问题及背景</font></h1><p>  肌萎缩性侧索硬化症(ALS)晚期患者或患有闭锁综合征的患者不能产生任何随意的肌肉运动，但这些疾病对大脑的感觉和认知功能影响很小，因此使用脑电图（electroencephalograph, EEG）来控制辅助设备为这些病人提供了一种与外界交流的可能方式<a href="#1">[1]</a>。想象肢体运动可以改变脑电活动，这种实验范式称为运动想象（motor imagery, MI），根据运动想象的类型可以获得不同的脑电模式。一种简单的通过运动想象实现控制的方式为区分对左右手运动的想象。<br />  由于容积传导效应的存在，原始的非侵入式脑电信号的空间分辨率较差，因此，为提高信噪比，空间滤波器在单次试验（trial）的分析中是非常有用的。</p><h1 id="二方法"><font size = 4>二、方法</font></h1><p>  用于处理脑电信号的一经典空间滤波方法为共空间模式（common spatial pattern, CSP）。CSP通过数据驱动的有监督的方式将原始传感器空间中的脑电信号投影至一个新的空间，使得空间滤波后的信号在一种情况下（一个类别）的方差最大，而在另一种情况下（另一个类别）方差最小<a href="#2">[2]</a>，即滤波后的数据包含了最有区分性的信息，因此在这之后很容易通过线性分类器分开。这也是CSP的根本原理。设计这种空间滤波器的方法是基于对两个协方差矩阵的同时对角化<a href="#1">[1]</a>。<br />  原始的单次试验的EEG数据可以表示为<span class="math inline">\(E_l\in R^{N\times T}\)</span>和<span class="math inline">\(E_r\in R^{N\times T}\)</span>，分别为想象左手运动与想象右手运动，其中<span class="math inline">\(N\)</span>是通道（采集数据的电极）数目，<span class="math inline">\(T\)</span>是采样点个数。预处理中的滤波去除了EEG中的常数部分，使得该分布的均值为0。</p><h1 id="csp的原始形式"><font size = 3>2.1 CSP的原始形式</font></h1><ol type="1"><li>首先按下式求得空间协方差矩阵并归一化。 <span class="math display">\[C_l=\frac{E_lE_l^*}{trace(E_lE_l^*)}\]</span> <span class="math display">\[C_r=\frac{E_rE_r^*}{trace(E_rE_r^*)}\]</span> 显然，协方差矩阵<span class="math inline">\(C_l\)</span>与<span class="math inline">\(C_r\)</span>是Hermite矩阵，同时也是半正定矩阵，且Hermite矩阵的特征值均为实数。</li><li>然后构建复合协方差矩阵，并对其进行白化处理（Whitening)。<br />复合协方差矩阵为 <span class="math display">\[C_c=C_l+C_r\]</span> 为去除信号中的冗余信息，需进行白化处理。矩阵白化的作用主要体现在两方面：<ul><li>减少特征之间的相关性</li><li>使特征具有相同的方差</li></ul></li></ol><p>  以上作用可以通过构建一白化矩阵<span class="math inline">\(P\)</span>，将复合协方差矩阵<span class="math inline">\(C_c\)</span>变换为单位矩阵<span class="math inline">\(I\)</span>表现出，这也是矩阵白化的方法，<span class="math inline">\(i.e.P^*C_cP=I\)</span>。<br />  因为<span class="math inline">\(C_c\)</span>为Hermite矩阵，为正规矩阵，可以酉对角化，故<span class="math inline">\(\exists\)</span>酉矩阵<span class="math inline">\(V\)</span>，<span class="math inline">\(V\)</span>为单位特征向量矩阵（每一列为特征向量），s.t.<span class="math display">\[V^*C_cV=D=\begin{bmatrix}\lambda_1^C &amp; &amp; &amp;\\&amp; \lambda_2^C &amp; &amp;\\&amp; &amp; \ddots &amp;\\&amp; &amp; &amp; \lambda_N^C\end{bmatrix} \]</span>   取白化矩阵<span class="math display">\[\begin{equation} P=V^*D^{-1/2}\label{10} \end{equation}\]</span>   则<span class="math display">\[P^*C_cP=I\]</span> 3. 计算空间滤波器<span class="math inline">\(W\)</span>。 <span class="math display">\[\begin{equation} I=P^*C_cP=P^*C_lP+P^*C_rP=S_l+S_r\label{100} \end{equation}\]</span>   设<span class="math inline">\(\lambda_j\)</span>为<span class="math inline">\(S_l\)</span>的特征值，对应的特征向量为<span class="math inline">\(v_j\)</span>，即 <span class="math display">\[S_lv_j=\lambda_jv_j\]</span>   又因为 <span class="math display">\[S_l+S_r=I\]</span>   所以 <span class="math display">\[(I-S_r)v_j=\lambda_jv_j\]</span>   上式可化为 <span class="math display">\[S_r v_j=(1-\lambda_j)v_j\]</span>   故<span class="math inline">\(v_j\)</span>也是<span class="math inline">\(S_r\)</span>的特征向量，而对应的特征值为<span class="math inline">\(1-\lambda_j\)</span>。所以矩阵<span class="math inline">\(S_l\)</span>与<span class="math inline">\(S_r\)</span>具有相同的特征向量，而对应的特征值之和为1。因为<span class="math inline">\(PCP^*=I\)</span>有相同的特征空间，所以这种方法称为共空间模式。<br />  因为<span class="math inline">\(S_l\)</span>与<span class="math inline">\(S_r\)</span>均为Hermite矩阵，均可以酉对角化。 <span class="math display">\[\begin{equation} S_l=UD_lU^*=U\begin{bmatrix}\lambda_1 &amp; &amp; &amp;\\&amp; \lambda_2 &amp; &amp;\\&amp; &amp; \ddots &amp;\\&amp; &amp; &amp; \lambda_N\end{bmatrix}U^*\label{101} \end{equation}\]</span> <span class="math display">\[\begin{equation} S_r=UD_rU^*=U\begin{bmatrix}1-\lambda_1 &amp; &amp; &amp;\\&amp; 1-\lambda_2 &amp; &amp;\\&amp; &amp; \ddots &amp;\\&amp; &amp; &amp; 1-\lambda_N\end{bmatrix}U^*\label{102} \end{equation}\]</span> <span class="math display">\[D_l+D_r=I\]</span>   同时，协方差矩阵为半正定矩阵，半正定矩阵的特征值均为非负，所以<span class="math inline">\(S_l\)</span>与<span class="math inline">\(S_r\)</span>的特征值均在0～1之间。显然，对角阵<span class="math inline">\(D_l\)</span>与<span class="math inline">\(D_r\)</span>对角线上的元素（特征值）为白化后的EEG（<span class="math inline">\(PE\)</span>）经矩阵<span class="math inline">\(U\)</span>的线性变换后得到的新矩阵的方差，所以最大与最小的<span class="math inline">\(\lambda_j\)</span>对应的特征向量可以将白化后的两类EEG数据旋转至最具区分性。<br />  将式<span class="math inline">\(\eqref{100}\)</span>分别与式<span class="math inline">\(\eqref{101}, \eqref{102}\)</span>联立可得 <span class="math display">\[PC_lP^*=UD_lU^*\]</span> <span class="math display">\[PC_rP^*=UD_rU^*\]</span>   所以 <span class="math display">\[(P^*U)^*C_lP^*U=D_l\]</span> <span class="math display">\[(P^*U)^*C_rP^*U=D_r\]</span>   因此，对原始EEG数据<span class="math inline">\(E_l\)</span>与<span class="math inline">\(E_r\)</span>进行的整体线性变换为<span class="math inline">\((P^*U)^*\)</span>，<span class="math inline">\(i.e.\)</span>空间滤波器<span class="math inline">\(W=P^*U\)</span>，空间滤波后的矩阵为 <span class="math display">\[Z=W^*E\]</span></p><h1 id="csp的第二种表述"><font size = 3>2.2 CSP的第二种表述</font></h1><p>  对以上推理过程进行总结，可得，CSP的计算思路是找到一个投影矩阵<span class="math inline">\(W\)</span>将这两个类别的EEG信号的协方差矩阵<span class="math inline">\(C_l\)</span>与<span class="math inline">\(C_r\)</span>对角化，且使得两对角阵的和为单位矩阵，即 <span class="math display">\[\begin{equation} W^*C_lW=D_l\label{11} \end{equation}\]</span> <span class="math display">\[\begin{equation} W^*C_rW=D_r\label{12} \end{equation}\]</span> <span class="math display">\[\begin{equation} D_l+D_r=I\label{13} \end{equation}\]</span> 将<span class="math inline">\(\eqref{11}\)</span>与<span class="math inline">\(\eqref{12}\)</span>相加，并将<span class="math inline">\(\eqref{13}\)</span>代入得 <span class="math display">\[\begin{equation} W^*(C_l+C_r)W=D_l+D_r=I\label{14} \end{equation}\]</span> <span class="math inline">\(\eqref{14}\)</span>与<span class="math inline">\(\eqref{11}\)</span>联立得 <span class="math display">\[\begin{equation} C_lW=(C_l+C_r)WD_l\label{16} \end{equation}\]</span> 式<span class="math inline">\(\eqref{16}\)</span>类似于特征向量的定义公式，实际上，若<span class="math inline">\(C_l+C_r\)</span>可逆，则可将其移至左侧，得到 <span class="math display">\[\begin{equation} (C_l+C_r)^{-1}C_lW=WD_l\label{17} \end{equation}\]</span> 此时，式<span class="math inline">\(\eqref{17}\)</span>恰为特征向量的定义公式。形如式<span class="math inline">\(\eqref{16}\)</span>称为广义特征值问题。而在大部分情况下<span class="math inline">\(C_l+C_r\)</span>是不可逆的，因此，接下来将推导广义特征值的求解。</p><h1 id="广义特征值问题"><font size = 3>2.2.1 广义特征值问题</font></h1><p>  广义特征值问题是关于方程 <span class="math display">\[\begin{equation} A\phi=\lambda B\phi\label{18} \end{equation}\]</span> 求解数值<span class="math inline">\(\lambda\)</span>，使得方程有非零解<span class="math inline">\(\phi\)</span>。其中，<span class="math inline">\(A, B\)</span>均为Hermite矩阵。方程<span class="math inline">\(\eqref{18}\)</span>的矩阵形式为 <span class="math display">\[\begin{equation} A\Phi=B\Phi\Lambda\label{22} \end{equation} \]</span>   其中，<span class="math inline">\(\Phi\)</span>与<span class="math inline">\(\Lambda\)</span>分别为特征向量矩阵与特征值矩阵，求解广义特征值问题即为求解这两个矩阵。</p><ul><li><span class="math inline">\(B\)</span>为正规矩阵，对其进行酉对角化 <span class="math display">\[\begin{equation} U_B^*BU_B=\Lambda_B\label{19} \end{equation}\]</span></li><li>根据式<span class="math inline">\(\eqref{10}\)</span>得到关于矩阵<span class="math inline">\(B\)</span>的白化矩阵为 <span class="math display">\[U_B&#39;=U_B\Lambda_B^{-1/2}\]</span>   使得 <span class="math display">\[U_B&#39;^* BU_B&#39;=I\]</span>   注意矩阵<span class="math inline">\(U_B&#39;\)</span>不是酉矩阵。</li><li>使用矩阵<span class="math inline">\(U_B&#39;\)</span>对矩阵<span class="math inline">\(A\)</span>进行变换 <span class="math display">\[U_B&#39;^* AU_B&#39;=(\Lambda_B^{-1/2}U_B^*)A(U_B\Lambda_B^{-1/2})=A&#39;\]</span> 注意因<span class="math inline">\(A&#39;^*=A&#39;\)</span>，矩阵<span class="math inline">\(A&#39;\)</span>仍为Hermite矩阵。</li><li><span class="math inline">\(A&#39;\)</span>为正规矩阵，对其进行酉对角化 <span class="math display">\[U_A^*A&#39;U_A=\Lambda\]</span>   i.e. <span class="math display">\[\begin{equation} U_A^*(\Lambda_B^{-1/2}U_B^*AU_B\Lambda_B^{-1/2})U_A=(U_A^*\Lambda_B^{-1/2}U_B^*)A(U_B\Lambda_B^{-1/2}U_A)=\Phi^*A\Phi=\Lambda\label{20} \end{equation}\]</span>   其中，定义 <span class="math display">\[\Phi=U_B\Lambda_B^{-1/2}U_A\]</span>   注意矩阵<span class="math inline">\(\Phi\)</span>不是酉矩阵。</li><li><span class="math inline">\(U\)</span>也可以将矩阵<span class="math inline">\(B\)</span>对角化 <span class="math display">\[\begin{equation} \Phi^*B\Phi=(U_A^*\Lambda_B^{-1/2})U_B^*BU_B(\Lambda_B^{-1/2}U_A)=U_A^*\Lambda_B^{-1/2}\Lambda_B\Lambda_B^{-1/2}U_A=U_A^*U_A=I\label{21} \end{equation}\]</span></li><li>将式<span class="math inline">\(\eqref{20}\)</span>和式<span class="math inline">\(\eqref{21}\)</span>结合可得到 <span class="math display">\[\left\{\begin{matrix}\Phi^*A\Phi=\Lambda(14)\\ \Phi^*B\Phi=I(15)\end{matrix}\right.\]</span>   在式<span class="math inline">\(\eqref{21}\)</span>的左右两边同时右乘<span class="math inline">\(\Lambda\)</span>，并将<span class="math inline">\(\eqref{20}\)</span>代入右边得到 <span class="math display">\[A\Phi=B\Phi\Lambda\]</span>   上式恰为式<span class="math inline">\(\eqref{22}\)</span>。因此，广义特征值问题的解在以上推导过程中求出。</li></ul><h1 id="广义瑞利商"><font size = 3>2.2.2 广义瑞利商</font></h1><p>  广义瑞利商的定义为 <span class="math display">\[R(w)=\frac{w^*Aw}{w^*Bw}\]</span>   其中，A, B均为Hermite矩阵，B为正定矩阵，<span class="math inline">\(w\in C^n\)</span>。显然，对<span class="math inline">\(w\)</span>进行等比例缩放不会影响瑞利商的值，i.e. <span class="math inline">\(R(w)=R(cw), c\in R, c\neq 0\)</span>。<br />  于是，可以确定合适的<span class="math inline">\(w\)</span>，令<span class="math inline">\(w^*Bw=1\)</span>，则<span class="math inline">\(R(w)=w^*Aw\)</span>。此时，对<span class="math inline">\(R(w)\)</span>求极值就是在约束<span class="math inline">\(w^*Bw=1\)</span>条件下对<span class="math inline">\(w^*Aw\)</span>求极值。利用拉格朗日乘子法求解，定义 <span class="math display">\[L(w,\lambda)=w^*Aw-\lambda(w^*Bw-1)\]</span>   然后求梯度取零 <span class="math display">\[\frac{d}{dw}L=Aw-\lambda Bw=0\]</span> 得到 <span class="math display">\[Aw=\lambda Bw=\frac{w^*Aw}{w^*Bw}Bw\]</span>   可以看出，上式与式<span class="math inline">\(\eqref{18}\)</span>相同，即，寻找<span class="math inline">\(w\)</span>使广义瑞利商<span class="math inline">\(R(w)\)</span>最大可以等价为求解A与B的广义特征值问题，并找到使特征值<span class="math inline">\(\lambda\)</span>最大所对应的特征向量<span class="math inline">\(w\)</span>。<br />  因此，之前得到的CSP的第二种表述（式<span class="math inline">\(\eqref{16}\)</span>）可以也变形为求解广义瑞利商的最大值问题。 即 <span class="math display">\[C_lW=(C_l+C_r)WD_l\Leftrightarrow \underset{w}{\mathrm{max}}\frac{w^*C_lw}{w^*(C_l+C_r)w}\]</span>   其中，<span class="math inline">\(W\)</span>矩阵是使广义瑞利商广义雷利商第一大、第二大至第N大的向量<span class="math inline">\(w\)</span>组成的矩阵。</p><h1 id="三数据及结果"><font size = 4>三、数据及结果</font></h1>  因为脑电信号往往是高维的，且包含大量噪声与伪迹，预处理过程也将对分类效果产生较大影响。因此本文使用随机生成的二维数据作为CSP滤波的例子，来解释CSP是如何工作的，并验证以上推导的CSP的两种表述方式的一致性。本例使用python进行编程及可视化展示，代码见附录。<br />  这两类数据是随机生成的高斯分布样本，具有相同的均值，协方差矩阵分别为 <span class="math display">\[\begin{bmatrix}10 &amp; -8\\-8 &amp;10 \end{bmatrix}, \begin{bmatrix}20 &amp; -8\\-8 &amp;5 \end{bmatrix} \]</span>   由此得到两组强相关但可分的数据，如图1左图所示。其中，两个椭圆表示的是每组数据的协方差，椭圆的旋转角度由协方差矩阵的特征向量得到，长短轴由协方差矩阵的特征值得到，因为特征向量表示椭圆长短轴的方向，而对应的特征值为轴的长度。使用以上两种方法分别计算可得到相同的投影矩阵。图中虚线为CSP投影的方向，这两个向量不是正交的，但他们与每一类最大方差的方向几乎是正交的。 右图为经过空间滤波后样本的分布，可以看出，这两类分布同时去相关，沿着纵轴红色类别具有最大的方差，而蓝色类别的方差最小；相反，沿着横轴蓝色类别具有最大的方差，而红色类别方差最小。 <img src="http://pic.yupoo.com/leelwre/3e1338bd/50951e19.png" /><center>图1 CSP空间滤波前后样本分布图</center><h1 id="参考"><font size = 4>参考</font></h1><p><span id="1">[1]Ramoser H, Muller-Gerking J, Pfurtscheller G. Optimal spatial filtering of single trial EEG during imagined hand movement[J]. IEEE transactions on rehabilitation engineering, 2000, 8(4): 441-446.</span><br /><span id="2">[2]Blankertz B, Tomioka R, Lemm S, et al. Optimizing spatial filters for robust EEG single-trial analysis[J]. IEEE Signal processing magazine, 2007, 25(1): 41-56.</span><br />[3]本文极大地参考了swolf的博客（<a href="https://mrswolf.github.io/zh-cn/2019/01/06/%E8%AF%A6%E8%A7%A3CSP/" target="_blank" rel="noopener">https://mrswolf.github.io/zh-cn/2019/01/06/%E8%AF%A6%E8%A7%A3CSP/</a>），这篇文章为我对CSP的了解提供了巨大的帮助。</p><h1 id="附录代码"><font size = 4>附录（代码）</font></h1><div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span><span id="cb1-2"><a href="#cb1-2"></a><span class="im">from</span> scipy.io <span class="im">import</span> loadmat</span><span id="cb1-3"><a href="#cb1-3"></a><span class="im">import</span> scipy.linalg <span class="im">as</span> linalg</span><span id="cb1-4"><a href="#cb1-4"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span><span id="cb1-5"><a href="#cb1-5"></a><span class="im">from</span> pdb <span class="im">import</span> set_trace</span><span id="cb1-6"><a href="#cb1-6"></a><span class="im">from</span> matplotlib.patches <span class="im">import</span> Ellipse</span><span id="cb1-7"><a href="#cb1-7"></a><span class="im">import</span> math</span><span id="cb1-8"><a href="#cb1-8"></a></span><span id="cb1-9"><a href="#cb1-9"></a><span class="co"># generate data</span></span><span id="cb1-10"><a href="#cb1-10"></a>mean1 <span class="op">=</span> [<span class="dv">0</span>,<span class="dv">0</span>]</span><span id="cb1-11"><a href="#cb1-11"></a>mean2 <span class="op">=</span> [<span class="dv">0</span>,<span class="dv">0</span>]</span><span id="cb1-12"><a href="#cb1-12"></a>cov1 <span class="op">=</span> [[<span class="dv">10</span>,<span class="op">-</span><span class="dv">8</span>],[<span class="op">-</span><span class="dv">8</span>,<span class="dv">10</span>]]</span><span id="cb1-13"><a href="#cb1-13"></a>cov2 <span class="op">=</span> [[<span class="dv">20</span>,<span class="op">-</span><span class="dv">8</span>],[<span class="op">-</span><span class="dv">8</span>,<span class="dv">5</span>]]</span><span id="cb1-14"><a href="#cb1-14"></a>X1 <span class="op">=</span> np.random.multivariate_normal(mean1, cov1, <span class="dv">150</span>).T</span><span id="cb1-15"><a href="#cb1-15"></a>X2 <span class="op">=</span> np.random.multivariate_normal(mean2, cov2, <span class="dv">150</span>).T</span><span id="cb1-16"><a href="#cb1-16"></a></span><span id="cb1-17"><a href="#cb1-17"></a></span><span id="cb1-18"><a href="#cb1-18"></a>X1 <span class="op">=</span> X1 <span class="op">-</span> X1.mean(axis<span class="op">=</span><span class="dv">1</span>,keepdims<span class="op">=</span><span class="va">True</span>)</span><span id="cb1-19"><a href="#cb1-19"></a>X2 <span class="op">=</span> X2 <span class="op">-</span> X2.mean(axis<span class="op">=</span><span class="dv">1</span>,keepdims<span class="op">=</span><span class="va">True</span>)</span><span id="cb1-20"><a href="#cb1-20"></a>X1 <span class="op">=</span> np.mat(X1)</span><span id="cb1-21"><a href="#cb1-21"></a>X2 <span class="op">=</span> np.mat(X2)</span><span id="cb1-22"><a href="#cb1-22"></a><span class="co"># normalization covariance</span></span><span id="cb1-23"><a href="#cb1-23"></a>C1 <span class="op">=</span> (X1<span class="op">*</span>X1.T)<span class="op">/</span>np.trace(X1<span class="op">*</span>X1.T)</span><span id="cb1-24"><a href="#cb1-24"></a>C2 <span class="op">=</span> (X2<span class="op">*</span>X2.T)<span class="op">/</span>np.trace(X2<span class="op">*</span>X2.T)</span><span id="cb1-25"><a href="#cb1-25"></a>C <span class="op">=</span> C1 <span class="op">+</span> C2</span><span id="cb1-26"><a href="#cb1-26"></a></span><span id="cb1-27"><a href="#cb1-27"></a><span class="co"># method one</span></span><span id="cb1-28"><a href="#cb1-28"></a><span class="co">## whitening matrix</span></span><span id="cb1-29"><a href="#cb1-29"></a>D_c, V_c <span class="op">=</span> linalg.eigh(C)</span><span id="cb1-30"><a href="#cb1-30"></a>isqrt_D_c <span class="op">=</span> np.diag(np.sqrt(<span class="dv">1</span><span class="op">/</span>D_c))</span><span id="cb1-31"><a href="#cb1-31"></a>P <span class="op">=</span> np.mat(isqrt_D_c)<span class="op">*</span>np.mat(V_c.T)</span><span id="cb1-32"><a href="#cb1-32"></a></span><span id="cb1-33"><a href="#cb1-33"></a>S1 <span class="op">=</span> P<span class="op">*</span>C1<span class="op">*</span>P.T</span><span id="cb1-34"><a href="#cb1-34"></a>S2 <span class="op">=</span> P<span class="op">*</span>C2<span class="op">*</span>P.T</span><span id="cb1-35"><a href="#cb1-35"></a><span class="co">## spatial filters</span></span><span id="cb1-36"><a href="#cb1-36"></a>D1, V <span class="op">=</span> linalg.eigh(S1)</span><span id="cb1-37"><a href="#cb1-37"></a>W <span class="op">=</span> P.T<span class="op">*</span>np.mat(V)</span><span id="cb1-38"><a href="#cb1-38"></a><span class="bu">print</span>(W)</span><span id="cb1-39"><a href="#cb1-39"></a></span><span id="cb1-40"><a href="#cb1-40"></a><span class="co"># # method two</span></span><span id="cb1-41"><a href="#cb1-41"></a><span class="co"># D1, W1 = linalg.eigh(C1,C)</span></span><span id="cb1-42"><a href="#cb1-42"></a><span class="co"># print(W)</span></span><span id="cb1-43"><a href="#cb1-43"></a></span><span id="cb1-44"><a href="#cb1-44"></a><span class="co"># projected data</span></span><span id="cb1-45"><a href="#cb1-45"></a>Z1 <span class="op">=</span> W.T<span class="op">*</span>X1</span><span id="cb1-46"><a href="#cb1-46"></a>Z2 <span class="op">=</span> W.T<span class="op">*</span>X2</span><span id="cb1-47"><a href="#cb1-47"></a></span><span id="cb1-48"><a href="#cb1-48"></a><span class="co"># generate covariance ellipse--raw data</span></span><span id="cb1-49"><a href="#cb1-49"></a>values1, vectors1 <span class="op">=</span> linalg.eigh(C1)</span><span id="cb1-50"><a href="#cb1-50"></a>values2, vectors2 <span class="op">=</span> linalg.eigh(C2)</span><span id="cb1-51"><a href="#cb1-51"></a>angle1 <span class="op">=</span> math.degrees(math.atan(vectors1[<span class="dv">0</span>][<span class="dv">1</span>]<span class="op">/</span>vectors1[<span class="dv">0</span>][<span class="dv">0</span>]))</span><span id="cb1-52"><a href="#cb1-52"></a>angle2 <span class="op">=</span> math.degrees(math.atan(vectors2[<span class="dv">0</span>][<span class="dv">1</span>]<span class="op">/</span>vectors2[<span class="dv">0</span>][<span class="dv">0</span>]))</span><span id="cb1-53"><a href="#cb1-53"></a></span><span id="cb1-54"><a href="#cb1-54"></a>e1 <span class="op">=</span> Ellipse(xy <span class="op">=</span> (<span class="dv">0</span>,<span class="dv">0</span>), width <span class="op">=</span> values1[<span class="dv">0</span>]<span class="op">*</span><span class="dv">10</span>, height <span class="op">=</span> values1[<span class="dv">1</span>]<span class="op">*</span><span class="dv">10</span>, angle<span class="op">=</span>angle1, edgecolor<span class="op">=</span><span class="st">&#39;orange&#39;</span>, fill <span class="op">=</span> <span class="va">False</span>, linewidth<span class="op">=</span><span class="dv">2</span>, zorder<span class="op">=</span><span class="dv">2</span>)</span><span id="cb1-55"><a href="#cb1-55"></a>e2 <span class="op">=</span> Ellipse(xy <span class="op">=</span> (<span class="dv">0</span>,<span class="dv">0</span>), width <span class="op">=</span> values2[<span class="dv">0</span>]<span class="op">*</span><span class="dv">10</span>, height <span class="op">=</span> values2[<span class="dv">1</span>]<span class="op">*</span><span class="dv">10</span>, angle<span class="op">=</span>angle2, edgecolor<span class="op">=</span><span class="st">&#39;c&#39;</span>, fill <span class="op">=</span> <span class="va">False</span>, linewidth<span class="op">=</span><span class="dv">2</span>, zorder<span class="op">=</span><span class="dv">2</span>)</span><span id="cb1-56"><a href="#cb1-56"></a></span><span id="cb1-57"><a href="#cb1-57"></a></span><span id="cb1-58"><a href="#cb1-58"></a><span class="co"># generate covariance ellipse--projected data</span></span><span id="cb1-59"><a href="#cb1-59"></a>C1 <span class="op">=</span> (Z1<span class="op">*</span>Z1.T)<span class="op">/</span>np.trace(Z1<span class="op">*</span>Z1.T)</span><span id="cb1-60"><a href="#cb1-60"></a>C2 <span class="op">=</span> (Z2<span class="op">*</span>Z2.T)<span class="op">/</span>np.trace(Z2<span class="op">*</span>Z2.T)</span><span id="cb1-61"><a href="#cb1-61"></a>values1, vectors1 <span class="op">=</span> linalg.eigh(C1)</span><span id="cb1-62"><a href="#cb1-62"></a>values2, vectors2 <span class="op">=</span> linalg.eigh(C2)</span><span id="cb1-63"><a href="#cb1-63"></a>angle1 <span class="op">=</span> math.degrees(math.atan(vectors1[<span class="dv">0</span>][<span class="dv">1</span>]<span class="op">/</span>vectors1[<span class="dv">0</span>][<span class="dv">0</span>]))</span><span id="cb1-64"><a href="#cb1-64"></a>angle2 <span class="op">=</span> math.degrees(math.atan(vectors2[<span class="dv">0</span>][<span class="dv">1</span>]<span class="op">/</span>vectors2[<span class="dv">0</span>][<span class="dv">0</span>]))</span><span id="cb1-65"><a href="#cb1-65"></a></span><span id="cb1-66"><a href="#cb1-66"></a>after_e1 <span class="op">=</span> Ellipse(xy <span class="op">=</span> (<span class="dv">0</span>,<span class="dv">0</span>), width <span class="op">=</span> values1[<span class="dv">0</span>]<span class="op">*</span><span class="dv">10</span>, height <span class="op">=</span> values1[<span class="dv">1</span>]<span class="op">*</span><span class="dv">10</span>, angle<span class="op">=</span>angle1, edgecolor<span class="op">=</span><span class="st">&#39;orange&#39;</span>, fill <span class="op">=</span> <span class="va">False</span>, linewidth<span class="op">=</span><span class="dv">2</span>, zorder<span class="op">=</span><span class="dv">2</span>)</span><span id="cb1-67"><a href="#cb1-67"></a>after_e2 <span class="op">=</span> Ellipse(xy <span class="op">=</span> (<span class="dv">0</span>,<span class="dv">0</span>), width <span class="op">=</span> values2[<span class="dv">0</span>]<span class="op">*</span><span class="dv">10</span>, height <span class="op">=</span> values2[<span class="dv">1</span>]<span class="op">*</span><span class="dv">10</span>, angle<span class="op">=</span>angle2, edgecolor<span class="op">=</span><span class="st">&#39;c&#39;</span>, fill <span class="op">=</span> <span class="va">False</span>, linewidth<span class="op">=</span><span class="dv">2</span>, zorder<span class="op">=</span><span class="dv">2</span>)</span><span id="cb1-68"><a href="#cb1-68"></a></span><span id="cb1-69"><a href="#cb1-69"></a></span><span id="cb1-70"><a href="#cb1-70"></a><span class="co"># plot</span></span><span id="cb1-71"><a href="#cb1-71"></a>fig <span class="op">=</span> plt.figure(<span class="dv">0</span>)</span><span id="cb1-72"><a href="#cb1-72"></a>ax1 <span class="op">=</span> fig.add_subplot(<span class="dv">121</span>, aspect<span class="op">=</span><span class="st">&#39;equal&#39;</span>)</span><span id="cb1-73"><a href="#cb1-73"></a>ax2 <span class="op">=</span> fig.add_subplot(<span class="dv">122</span>, aspect<span class="op">=</span><span class="st">&#39;equal&#39;</span>)</span><span id="cb1-74"><a href="#cb1-74"></a></span><span id="cb1-75"><a href="#cb1-75"></a>ax1.plot(X1[<span class="dv">0</span>],X1[<span class="dv">1</span>],<span class="st">&#39;ro&#39;</span>)</span><span id="cb1-76"><a href="#cb1-76"></a>ax1.plot(X2[<span class="dv">0</span>],X2[<span class="dv">1</span>],<span class="st">&#39;bo&#39;</span>)</span><span id="cb1-77"><a href="#cb1-77"></a>ax1.add_artist(e1)</span><span id="cb1-78"><a href="#cb1-78"></a>ax1.add_artist(e2)</span><span id="cb1-79"><a href="#cb1-79"></a>ax1.set_xlim(<span class="op">-</span><span class="dv">15</span>, <span class="dv">15</span>)</span><span id="cb1-80"><a href="#cb1-80"></a>ax1.set_ylim(<span class="op">-</span><span class="dv">15</span>, <span class="dv">15</span>)</span><span id="cb1-81"><a href="#cb1-81"></a>ax1.grid(<span class="va">True</span>)</span><span id="cb1-82"><a href="#cb1-82"></a>x <span class="op">=</span> np.arange(<span class="op">-</span><span class="dv">10</span>,<span class="dv">10</span>,<span class="fl">0.1</span>)</span><span id="cb1-83"><a href="#cb1-83"></a>ax1.plot(x,W[<span class="dv">0</span>][<span class="dv">1</span>]<span class="op">/</span>W[<span class="dv">0</span>][<span class="dv">0</span>]<span class="op">*</span>x,<span class="st">&#39;b--&#39;</span>)</span><span id="cb1-84"><a href="#cb1-84"></a>ax1.plot(x,W[<span class="dv">1</span>][<span class="dv">1</span>]<span class="op">/</span>W[<span class="dv">1</span>][<span class="dv">0</span>]<span class="op">*</span>x,<span class="st">&#39;r--&#39;</span>)</span><span id="cb1-85"><a href="#cb1-85"></a>ax1.set_title(<span class="st">&#39;Before CSP Filtering&#39;</span>)</span><span id="cb1-86"><a href="#cb1-86"></a>ax1.plot()</span><span id="cb1-87"><a href="#cb1-87"></a></span><span id="cb1-88"><a href="#cb1-88"></a>ax2.plot(Z1[<span class="dv">0</span>],Z1[<span class="dv">1</span>],<span class="st">&#39;ro&#39;</span>)</span><span id="cb1-89"><a href="#cb1-89"></a>ax2.plot(Z2[<span class="dv">0</span>],Z2[<span class="dv">1</span>],<span class="st">&#39;bo&#39;</span>)</span><span id="cb1-90"><a href="#cb1-90"></a>ax2.add_artist(after_e1)</span><span id="cb1-91"><a href="#cb1-91"></a>ax2.add_artist(after_e2)</span><span id="cb1-92"><a href="#cb1-92"></a>ax2.set_xlim(<span class="op">-</span><span class="dv">15</span>, <span class="dv">15</span>)</span><span id="cb1-93"><a href="#cb1-93"></a>ax2.set_ylim(<span class="op">-</span><span class="dv">15</span>, <span class="dv">15</span>)</span><span id="cb1-94"><a href="#cb1-94"></a>ax2.set_title(<span class="st">&#39;After CSP Filtering&#39;</span>)</span><span id="cb1-95"><a href="#cb1-95"></a>ax2.grid(<span class="va">True</span>)</span><span id="cb1-96"><a href="#cb1-96"></a>ax2.plot()</span><span id="cb1-97"><a href="#cb1-97"></a></span><span id="cb1-98"><a href="#cb1-98"></a>plt.show()</span></code></pre></div>]]></content>
      
      
      <categories>
          
          <category> BCI </category>
          
      </categories>
      
      
    </entry>
    
    
  
  
</search>
